{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MusicGroup Machine Learning Test\n",
    "\n",
    "Marc Siquier Penyafort  \n",
    "marcsiquierpenyafort@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all necessary packages and functions from utils file\n",
    "I will use `sklearn` in order to train and test GMMs and to evaluate the results.   \n",
    "Warnings appear when setting a high train percentage and (as the test dataset is very small) 0 instances are classified for a given class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch all json database files in `databaseDir` directory.\n",
    "**Note:** Please set-up your `databaseDir` to the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of json files fetched: 2831\n"
     ]
    }
   ],
   "source": [
    "databaseDir = '/home/msiquier/Documents/music_group_ml_test/music_group_ml_test_data'\n",
    "jsonfiles = fetchFiles(databaseDir, '.json')\n",
    "print \"Number of json files fetched: \" + str(len(jsonfiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and divide dataset \n",
    "Here I import all samples from the fetched json files taking into account that each file can contain more than one sample.   \n",
    "The `data` structure is a python dictionary with the different instruments as keys and for each instrument a list of feature vectors is given. We can also convert it to XY vectors using `convertToXY` but I will go on with the dict structure.   \n",
    "Afterwards I divide randomly the dataset into train and test (keeping the dict structure) and ensuring that every class has a given percentage of train samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created training and testing sets with the following number of samples:\n",
      "\n",
      "\tTrain\tTest\tTotal\tClass\n",
      "\n",
      "\t384\t164\t548\thihat\n",
      "\t1181\t506\t1687\tbass\n",
      "\t2397\t1026\t3423\tguitar\n",
      "\t161\t69\t230\tsaxophone\n",
      "\t281\t120\t401\ttom\n",
      "\t698\t299\t997\tvocals\n",
      "\t281\t120\t401\tsnare\n",
      "\t546\t233\t779\tpiano\n",
      "\t283\t120\t403\tkick\n",
      "\n",
      "\t6212\t2657\t8869\tTOTAL\n"
     ]
    }
   ],
   "source": [
    "data = importData(jsonfiles)\n",
    "#X, Y = convertToXY(data)\n",
    "train, test = randomTrainTest(data, percentage_train=0.7)\n",
    "printDataStats(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have 9 different classes with a total of 8869 samples.   \n",
    "Dividing the dataset into train and test with a train percentage of 0.7 we obtain 6212 training samples and 2657 test samples.   \n",
    "As we have different number of instances per class we say it is a unbalanced dataset and probabilistic generative models such as GMMs are known for work properly with this type of datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute and Score GMMs\n",
    "Here I will compute a GMM for each class with the train dataset using 6 gaussian components and full (each component has its own general covariance matrix) covariance matrix.  \n",
    "As predicted class I take the GMM with best score for each test sample.   \n",
    "**Note:**: As we divide the dataset randomly, results vary for each execution of the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       bass       0.94      0.87      0.91       506\n",
      "     guitar       0.90      0.97      0.93      1026\n",
      "      hihat       0.86      0.80      0.83       164\n",
      "       kick       0.89      0.82      0.86       120\n",
      "      piano       0.98      0.95      0.97       233\n",
      "  saxophone       0.96      0.77      0.85        69\n",
      "      snare       0.91      0.80      0.85       120\n",
      "        tom       0.85      0.82      0.84       120\n",
      "     vocals       0.86      0.93      0.89       299\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2657\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[441  52   1   7   0   0   0   5   0]\n",
      " [ 12 994   5   0   3   2   3   0   7]\n",
      " [  1   1 131   0   0   0   3   0  28]\n",
      " [  5   5   0  99   0   0   0  11   0]\n",
      " [  0  11   0   0 222   0   0   0   0]\n",
      " [  0   8   0   0   1  53   0   0   7]\n",
      " [  1  11   8   0   0   0  96   2   2]\n",
      " [  5   8   0   5   0   0   3  99   0]\n",
      " [  3  11   8   0   0   0   0   0 277]]\n"
     ]
    }
   ],
   "source": [
    "gmms = computeGMMS(train, n_components=6, covariance_type='full')\n",
    "correct, predicted = scoreGMMS(gmms, test)\n",
    "classificationReport(correct, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-Tuning the models\n",
    "Now that we see that this models work great with this dataset, I will try to fine tune some of its parameters such as number of components and covarince matrix type. In order to avoid execution dependant results, I am running each iteration 10 times (dividing dataset, training and testing) and I return the average of the 10 results.\n",
    "\n",
    "Here we test how the model works varying the number of gaussian components and the covariance type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "covariance\tcomp\tPrec\tRec\tf1-s\n",
      "\n",
      "spherical\t1\t0.904\t0.897\t0.897\n",
      "spherical\t2\t0.908\t0.903\t0.903\n",
      "spherical\t3\t0.912\t0.910\t0.909\n",
      "spherical\t4\t0.913\t0.911\t0.911\n",
      "spherical\t5\t0.912\t0.911\t0.910\n",
      "spherical\t6\t0.910\t0.909\t0.908\n",
      "spherical\t7\t0.910\t0.908\t0.906\n",
      "spherical\t8\t0.904\t0.902\t0.899\n",
      "spherical\t9\t0.898\t0.894\t0.889\n",
      "spherical\t10\t0.897\t0.892\t0.887\n",
      "\n",
      "covariance\tcomp\tPrec\tRec\tf1-s\n",
      "\n",
      "diag    \t1\t0.905\t0.896\t0.896\n",
      "diag    \t2\t0.908\t0.904\t0.903\n",
      "diag    \t3\t0.909\t0.906\t0.906\n",
      "diag    \t4\t0.912\t0.911\t0.910\n",
      "diag    \t5\t0.913\t0.911\t0.910\n",
      "diag    \t6\t0.910\t0.908\t0.908\n",
      "diag    \t7\t0.910\t0.908\t0.907\n",
      "diag    \t8\t0.907\t0.904\t0.902\n",
      "diag    \t9\t0.900\t0.895\t0.890\n",
      "diag    \t10\t0.894\t0.890\t0.882\n",
      "\n",
      "covariance\tcomp\tPrec\tRec\tf1-s\n",
      "\n",
      "tied    \t1\t0.907\t0.899\t0.899\n",
      "tied    \t2\t0.910\t0.905\t0.905\n",
      "tied    \t3\t0.913\t0.910\t0.910\n",
      "tied    \t4\t0.913\t0.911\t0.911\n",
      "tied    \t5\t0.913\t0.912\t0.911\n",
      "tied    \t6\t0.912\t0.910\t0.909\n",
      "tied    \t7\t0.907\t0.905\t0.903\n",
      "tied    \t8\t0.904\t0.902\t0.900\n",
      "tied    \t9\t0.903\t0.899\t0.894\n",
      "tied    \t10\t0.898\t0.893\t0.887\n",
      "\n",
      "covariance\tcomp\tPrec\tRec\tf1-s\n",
      "\n",
      "full    \t1\t0.911\t0.903\t0.904\n",
      "full    \t2\t0.912\t0.908\t0.908\n",
      "full    \t3\t0.910\t0.907\t0.906\n",
      "full    \t4\t0.910\t0.908\t0.908\n",
      "full    \t5\t0.911\t0.909\t0.908\n",
      "full    \t6\t0.911\t0.909\t0.909\n",
      "full    \t7\t0.909\t0.906\t0.905\n",
      "full    \t8\t0.904\t0.901\t0.898\n",
      "full    \t9\t0.900\t0.896\t0.891\n",
      "full    \t10\t0.895\t0.889\t0.882\n"
     ]
    }
   ],
   "source": [
    "for cov_type in ['spherical', 'diag', 'tied', 'full']:\n",
    "    print '\\ncovariance\\tcomp\\tPrec\\tRec\\tf1-s\\n'\n",
    "    for comp in range(1,11,1):\n",
    "        stats = runXtimes(data, percentage_train=0.7, n_components=comp, covariance_type=cov_type, nruns=20)\n",
    "        print '{:<8}\\t{}\\t'.format(cov_type, comp) + '\\t'.join(['%.3f' % a for a in stats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter\tPrec\tRec\tf1-s\n",
      "\n",
      "1\t0.914\t0.911\t0.910\n",
      "2\t0.917\t0.916\t0.915\n",
      "3\t0.911\t0.906\t0.906\n",
      "4\t0.905\t0.900\t0.899\n",
      "5\t0.909\t0.906\t0.906\n",
      "6\t0.917\t0.915\t0.915\n",
      "7\t0.913\t0.910\t0.910\n",
      "8\t0.903\t0.900\t0.899\n",
      "9\t0.917\t0.916\t0.915\n",
      "10\t0.907\t0.906\t0.905\n",
      "\n",
      "avg:\t0.911\t0.909\t0.908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats = runXtimes(data, percentage_train=0.7, n_components=4, covariance_type='tied', nruns=10, printa=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter\tPrec\tRec\tf1-s\n",
      "\n",
      "1\t0.918\t0.899\t0.901\n",
      "2\t0.919\t0.896\t0.898\n",
      "3\t0.936\t0.932\t0.933\n",
      "4\t0.935\t0.931\t0.931\n",
      "5\t0.933\t0.927\t0.928\n",
      "6\t0.916\t0.890\t0.894\n",
      "7\t0.912\t0.889\t0.891\n",
      "8\t0.906\t0.874\t0.877\n",
      "9\t0.905\t0.885\t0.885\n",
      "10\t0.923\t0.906\t0.910\n",
      "\n",
      "avg:\t0.920\t0.903\t0.905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_norm = normalize_data(data)\n",
    "stats = runXtimes(data_norm, percentage_train=0.7, n_components=4, covariance_type='tied', nruns=10, printa=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
